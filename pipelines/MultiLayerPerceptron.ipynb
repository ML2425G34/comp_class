{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9d41b10-0c77-40e2-ac8c-44ebdfca6114",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca557089-8255-4d01-b414-4dcb3bbdfdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import ast\n",
    "import inspect\n",
    "from collections.abc import Iterable\n",
    "\n",
    "# Base Classes & Estimators\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Pipeline & Model Construction\n",
    "from imblearn.pipeline import Pipeline as imPipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Preprocessing & Transformation\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import RFE, SelectKBest\n",
    "\n",
    "# Handling Imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import ElasticNet, LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model Tuning & Cross-validation\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate, StratifiedKFold, train_test_split\n",
    "\n",
    "# Model Evaluation & Scoring\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7237db99-4514-4227-a012-f519349cd5b9",
   "metadata": {},
   "source": [
    "# Custom Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1c2b034-caae-4917-8f6c-81813eb6e758",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierClipper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower_percentile=0.005, upper_percentile=0.995, use_iqr=False):\n",
    "        \"\"\"\n",
    "        Initialize the OutlierClipper with options for percentile clipping or IQR-based clipping.\n",
    "\n",
    "        Parameters:\n",
    "        - lower_percentile: float, lower bound percentile for clipping (if percentiles are used)\n",
    "        - upper_percentile: float, upper bound percentile for clipping (if percentiles are used)\n",
    "        - use_iqr: bool, whether to use IQR method for determining bounds\n",
    "        \"\"\"\n",
    "        self.lower_percentile = lower_percentile\n",
    "        self.upper_percentile = upper_percentile\n",
    "        self.use_iqr = use_iqr\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fit the clipping bounds based on the training dataset using the specified method (percentiles or IQR).\n",
    "\n",
    "        Parameters:\n",
    "        - X: numpy.ndarray or pandas.DataFrame, the dataset used for fitting\n",
    "        - y: ignored, not used for fitting\n",
    "\n",
    "        Returns:\n",
    "        - self: fitted instance of the class\n",
    "        \"\"\"\n",
    "        # Convert to DataFrame if input is numpy array\n",
    "        X = pd.DataFrame(X) if not isinstance(X, pd.DataFrame) else X\n",
    "        \n",
    "        # For each column in X, calculate the bounds using the specified method\n",
    "        self.bounds_ = {}\n",
    "        for column in X.columns:\n",
    "            if self.use_iqr:\n",
    "                q1 = X[column].quantile(0.25)  # 1st quartile\n",
    "                q3 = X[column].quantile(0.75)  # 3rd quartile\n",
    "                iqr = q3 - q1  # Interquartile range\n",
    "                lower_bound = q1 - 1.5 * iqr\n",
    "                upper_bound = q3 + 1.5 * iqr\n",
    "            else:\n",
    "                lower_bound = X[column].quantile(self.lower_percentile)\n",
    "                upper_bound = X[column].quantile(self.upper_percentile)\n",
    "\n",
    "            self.bounds_[column] = (lower_bound, upper_bound)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Apply clipping to the dataset based on the fitted bounds.\n",
    "\n",
    "        Parameters:\n",
    "        - X: numpy.ndarray or pandas.DataFrame, the dataset to transform\n",
    "\n",
    "        Returns:\n",
    "        - X: pandas.DataFrame, the transformed dataset with clipped values\n",
    "        \"\"\"\n",
    "        # Convert to DataFrame if input is numpy array\n",
    "        X = pd.DataFrame(X) if not isinstance(X, pd.DataFrame) else X\n",
    "\n",
    "        # Apply clipping for each column\n",
    "        for column, (lower_bound, upper_bound) in self.bounds_.items():\n",
    "            X[column] = X[column].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0de57347-467e-4d23-9175-fe9803c7f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrequencyEncoder(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        # Compute the frequency counts for each column in the DataFrame\n",
    "        self.freq_map = X.apply(pd.Series.value_counts)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Apply the frequency counts to transform the data\n",
    "        return X.apply(lambda col: col.map(self.freq_map[col.name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d9999c-088c-40b1-8b6f-5d1304df3c30",
   "metadata": {},
   "source": [
    "# Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b3b112-689d-4a91-bb32-589dc38acbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data ingestion with dtype application directly\n",
    "with open('../data/dtypes.json', 'r') as file:\n",
    "    dtypes = json.load(file)\n",
    "train = pd.read_csv('../data/preproc_train.csv', index_col=0, dtype=dtypes, low_memory=True)\n",
    "test = pd.read_csv('../data/preproc_test.csv', index_col=0, dtype=dtypes, low_memory=True)\n",
    "\n",
    "# Get unique values and create a mapping dictionary\n",
    "unique_values = train['claim_injury_type'].unique()\n",
    "mapping = {value: int(value[0]) - 1 for value in unique_values}\n",
    "\n",
    "# Handle NaN and target variable creation\n",
    "train = train.fillna(np.nan)\n",
    "X = train.drop(columns=['claim_injury_type'])\n",
    "\n",
    "# Encode the target values\n",
    "y = train['claim_injury_type'].map(mapping).astype(int)\n",
    "\n",
    "# Example of decoding\n",
    "decoded_values = y.map(inverse_mapping)\n",
    "\n",
    "y = train['claim_injury_type'].map(lambda x: int(x[0]) - 1).astype(int)\n",
    "\n",
    "# Extract rows where y is in [6, 7, 8], then sample remaining rows to match size\n",
    "rows_with_78 = y.isin([6, 7])\n",
    "X_with_78, y_with_78 = X[rows_with_78], y[rows_with_78]\n",
    "\n",
    "# Sample from the rest of the data\n",
    "X_remaining, y_remaining = X[~rows_with_78], y[~rows_with_78]\n",
    "remaining_sample_size = 10000 - len(X_with_78)\n",
    "X_sampled, y_sampled = X_remaining.sample(remaining_sample_size, random_state=42), y_remaining.loc[X_remaining.sample(remaining_sample_size, random_state=42).index]\n",
    "\n",
    "# Concatenate the data\n",
    "X, y = pd.concat([X_with_78, X_sampled]), pd.concat([y_with_78, y_sampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf420dce-7ed3-435e-9747-fa9cd8f1c9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_features = [\n",
    "    'age_at_injury', 'ime_4_count', 'average_weekly_wage', 'birth_year', 'number_of_dependents', 'dd_asb_c2', 'dd_asb_c3', 'dd_c2_c3',\n",
    "    'first_hearing_date_day', 'first_hearing_date_month', 'first_hearing_date_year', 'c_2_date_day', 'c_2_date_month', 'c_2_date_year',\n",
    "    'c_3_date_day', 'c_3_date_month', 'c_3_date_year', 'assembly_date_day', 'assembly_date_month', 'assembly_date_year',\n",
    "    'accident_date_day', 'accident_date_month', 'accident_date_year', 'avg_word_emb_dim_0', 'avg_word_emb_dim_1', 'avg_word_emb_dim_2',\n",
    "    'avg_word_emb_dim_3', 'avg_word_emb_dim_4', 'avg_word_emb_dim_5', 'avg_word_emb_dim_6', 'avg_word_emb_dim_7', 'avg_word_emb_dim_8',\n",
    "    'avg_word_emb_dim_9', 'var_word_emb_dim_0', 'var_word_emb_dim_1', 'var_word_emb_dim_2', 'var_word_emb_dim_3', 'var_word_emb_dim_4',\n",
    "    'var_word_emb_dim_5', 'var_word_emb_dim_6', 'var_word_emb_dim_7', 'var_word_emb_dim_8', 'var_word_emb_dim_9', 'euclidean_norm'\n",
    "]\n",
    "\n",
    "binary_features = [\n",
    "    'age_at_injury_zero', 'is_unionized', 'alternative_dispute_resolution', 'attorney_representative', 'covid_19_indicator', 'do_1', 'do_10',\n",
    "    'do_11', 'do_12', 'do_13', 'do_14', 'do_15', 'do_16', 'do_2', 'do_3', 'do_4', 'do_5', 'do_6', 'do_7', 'do_8', 'do_9', 'missing_accident_date',\n",
    "    'missing_age_at_injury', 'missing_average_weekly_wage', 'missing_birth_year', 'missing_c_2_date', 'missing_c_3_date', 'missing_first_hearing_date',\n",
    "    'missing_gender', 'missing_ime_4_count', 'missing_industry_code', 'missing_industry_code_description', 'missing_wcio_cause_of_injury_code',\n",
    "    'missing_wcio_cause_of_injury_description', 'missing_wcio_nature_of_injury_code', 'missing_wcio_nature_of_injury_description',\n",
    "    'missing_wcio_part_of_body_code', 'missing_wcio_part_of_body_description', 'missing_zip_code'\n",
    "]\n",
    "\n",
    "hot_columns = [\"carrier_type\", \"part_of_body_group\", \"cause_of_injury_group\", \"medical_fee_region\"]\n",
    "frequency_columns = [\"industry_code\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93523a47-6e62-4f82-88c7-ae83ac64b216",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deb78696-62b1-4e3a-98b7-f31fffbe50c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = imPipeline(steps=[\n",
    "    ('column_transformer', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('onehotencoder', OneHotEncoder(), hot_columns),  # OneHotEncoder for categorical variables in 'hot_columns'\n",
    "            ('frequencyencoder', FrequencyEncoder(), frequency_columns),  # Frequency encoding for categorical variables in 'frequency_columns'\n",
    "            ('outlier_clipper', OutlierClipper(), metric_features)  # Outlier clipping for 'metric_features'\n",
    "        ]\n",
    "    )),\n",
    "    ('scaler', MinMaxScaler()),  # MinMaxScaler to normalize feature values between 0 and 1\n",
    "    ('knnimputer', KNNImputer(weights='uniform')),  # KNN imputation to fill missing values based on nearest neighbors (uniform weights)\n",
    "    ('feature_selection', RFE(estimator=ElasticNet(), step=2)),  # Recursive Feature Elimination (RFE) for selecting features, using ElasticNet as estimator\n",
    "    ('smote', SMOTE(sampling_strategy='auto', random_state=42)),  # SMOTE to handle class imbalance by generating synthetic samples\n",
    "    ('mlp', MLPClassifier(solver='adam', max_iter=300))  # Multi-layer Perceptron classifier with 'adam' optimizer and a max of 300 iterations for training\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "951a39a0-917a-4926-8731-e1fd5858928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \n",
    "    # ElasticNet hyperparameters\n",
    "    'feature_selection__n_features_to_select': [25, 50], # Number of features to select\n",
    "    \n",
    "    # KNNImputer hyperparameters\n",
    "    'knnimputer__n_neighbors': [3, 5],  # Number of neighbors for imputation\n",
    "    \n",
    "    # MLPClassifier hyperparameters\n",
    "    'mlp__hidden_layer_sizes': [(64, 32), (128, 64), (256, 128, 64)],  # Chosen architectures\n",
    "    'mlp__learning_rate_init': [0.05, 0.1],  # Learning rate\n",
    "    'mlp__alpha': [0.001, 0.01]  # Regularization strength for MLP\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae714aa2-daaa-40d1-96c6-1af2c3661c76",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b07187da-e16a-4d70-b43d-a2cb4570afb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.5s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.3s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.9s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   8.1s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   6.5s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=  12.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   4.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   3.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=  10.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   7.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   4.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.5s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   4.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   1.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=  11.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   9.9s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   4.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   9.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   3.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   3.3s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   4.9s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   8.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   8.9s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   8.5s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=  11.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.9s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.9s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   3.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   5.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   5.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   9.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   5.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   8.2s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   8.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.3s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   5.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   2.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   7.2s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=  11.2s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   4.9s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=  10.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   4.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.7s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   7.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.7s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=  11.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   9.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   4.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.2s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.2s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.9s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.2s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   4.3s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   9.3s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   5.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=  13.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   5.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nottoriousgg/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/model_selection/_search.py:412: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(param_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 8.0min\n",
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.3s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.1s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   3.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.9s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   4.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   6.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=  10.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   5.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   7.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.5s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.3s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.5s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.9s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   1.9s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=  12.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   7.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   4.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.5s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.9s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.3s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   9.5s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   6.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   3.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   4.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.5s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.1s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   5.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=  12.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=  11.5s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   7.3s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.7s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.7s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   2.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.3s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.9s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   9.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   8.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   3.7s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   5.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   1.7s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.2s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   5.9s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   5.7s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   4.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.3s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.9s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.7s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   4.9s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   7.3s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   9.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=  10.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.3s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   6.3s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   6.3s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nottoriousgg/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/model_selection/_search.py:412: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(param_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 7.3min\n",
      "Fitting 2 folds for each of 48 candidates, totalling 96 fits\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   4.1s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   5.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   9.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=  12.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=  10.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   4.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   4.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.1s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   5.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.9s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.5s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   6.9s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   7.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.1s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   8.3s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   4.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   3.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.3s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   1.9s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   6.9s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   8.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   8.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   7.6s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   3.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.1s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.8s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.2s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   4.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   7.4s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   5.0s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   8.7s\n",
      "[CV] END feature_selection__n_features_to_select=25, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   8.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.3s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   6.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.9s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   7.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   7.3s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   8.3s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   5.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.9s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   8.7s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   6.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   7.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=3, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   4.7s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   3.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   2.4s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   4.7s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   2.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   4.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   7.9s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   7.7s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.001, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   8.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.05; total time=   2.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.6s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(64, 32), mlp__learning_rate_init=0.1; total time=   1.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   3.2s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.05; total time=   2.8s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   2.1s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(128, 64), mlp__learning_rate_init=0.1; total time=   3.0s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   8.5s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.05; total time=   8.2s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.2s\n",
      "[CV] END feature_selection__n_features_to_select=50, knnimputer__n_neighbors=5, mlp__alpha=0.01, mlp__hidden_layer_sizes=(256, 128, 64), mlp__learning_rate_init=0.1; total time=   6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nottoriousgg/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/model_selection/_search.py:412: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(param_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END .................................................... total time= 7.7min\n"
     ]
    }
   ],
   "source": [
    "outer_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "inner_cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_macro',\n",
    "    cv=inner_cv,\n",
    "    n_jobs=1,\n",
    "    refit=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Perform cross-validation using GridSearchCV with outer cross-validation\n",
    "cv_results = cross_validate(\n",
    "    estimator=grid_search,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    cv=outer_cv,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    "    scoring=\"f1_macro\",\n",
    "    n_jobs=1,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d88ffc2-7bd8-4539-9934-671c4158df7b",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bcc762e-fdba-430e-b843-56f373ef414e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation results saved to ../results/cv_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert cv_results to a pandas DataFrame\n",
    "cv_results_df = pd.DataFrame(cv_results)\n",
    "\n",
    "# Specify the file path (in the current working directory)\n",
    "file_path = '../results/cv_results.csv'\n",
    "\n",
    "# Append the DataFrame to the CSV file (if it exists) or create a new one\n",
    "cv_results_df.to_csv(file_path, mode='a', header=not pd.io.common.file_exists(file_path), index=False)\n",
    "\n",
    "print(f\"Cross-validation results saved to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7dbcb21-601e-48b1-b359-dab9d323be4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  [&#x27;carrier_type&#x27;,\n",
       "                                                   &#x27;part_of_body_group&#x27;,\n",
       "                                                   &#x27;cause_of_injury_group&#x27;,\n",
       "                                                   &#x27;medical_fee_region&#x27;]),\n",
       "                                                 (&#x27;frequencyencoder&#x27;,\n",
       "                                                  FrequencyEncoder(),\n",
       "                                                  [&#x27;industry_code&#x27;]),\n",
       "                                                 (&#x27;outlier_clipper&#x27;,\n",
       "                                                  OutlierClipper(),\n",
       "                                                  [&#x27;age_at_injury&#x27;,\n",
       "                                                   &#x27;ime_4_count&#x27;,\n",
       "                                                   &#x27;average_weekly_wage&#x27;,\n",
       "                                                   &#x27;birth_year&#x27;,\n",
       "                                                   &#x27;nu...\n",
       "                                                   &#x27;avg_word_emb_dim_3&#x27;,\n",
       "                                                   &#x27;avg_word_emb_dim_4&#x27;,\n",
       "                                                   &#x27;avg_word_emb_dim_5&#x27;,\n",
       "                                                   &#x27;avg_word_emb_dim_6&#x27;, ...])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;knnimputer&#x27;, KNNImputer(n_neighbors=3)),\n",
       "                (&#x27;feature_selection&#x27;,\n",
       "                 RFE(estimator=ElasticNet(), n_features_to_select=50, step=2)),\n",
       "                (&#x27;smote&#x27;, SMOTE(random_state=42)),\n",
       "                (&#x27;mlp&#x27;,\n",
       "                 MLPClassifier(alpha=0.001, hidden_layer_sizes=(128, 64),\n",
       "                               learning_rate_init=0.05))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;Pipeline<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;column_transformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  [&#x27;carrier_type&#x27;,\n",
       "                                                   &#x27;part_of_body_group&#x27;,\n",
       "                                                   &#x27;cause_of_injury_group&#x27;,\n",
       "                                                   &#x27;medical_fee_region&#x27;]),\n",
       "                                                 (&#x27;frequencyencoder&#x27;,\n",
       "                                                  FrequencyEncoder(),\n",
       "                                                  [&#x27;industry_code&#x27;]),\n",
       "                                                 (&#x27;outlier_clipper&#x27;,\n",
       "                                                  OutlierClipper(),\n",
       "                                                  [&#x27;age_at_injury&#x27;,\n",
       "                                                   &#x27;ime_4_count&#x27;,\n",
       "                                                   &#x27;average_weekly_wage&#x27;,\n",
       "                                                   &#x27;birth_year&#x27;,\n",
       "                                                   &#x27;nu...\n",
       "                                                   &#x27;avg_word_emb_dim_3&#x27;,\n",
       "                                                   &#x27;avg_word_emb_dim_4&#x27;,\n",
       "                                                   &#x27;avg_word_emb_dim_5&#x27;,\n",
       "                                                   &#x27;avg_word_emb_dim_6&#x27;, ...])])),\n",
       "                (&#x27;scaler&#x27;, MinMaxScaler()),\n",
       "                (&#x27;knnimputer&#x27;, KNNImputer(n_neighbors=3)),\n",
       "                (&#x27;feature_selection&#x27;,\n",
       "                 RFE(estimator=ElasticNet(), n_features_to_select=50, step=2)),\n",
       "                (&#x27;smote&#x27;, SMOTE(random_state=42)),\n",
       "                (&#x27;mlp&#x27;,\n",
       "                 MLPClassifier(alpha=0.001, hidden_layer_sizes=(128, 64),\n",
       "                               learning_rate_init=0.05))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;column_transformer: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for column_transformer: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;onehotencoder&#x27;, OneHotEncoder(),\n",
       "                                 [&#x27;carrier_type&#x27;, &#x27;part_of_body_group&#x27;,\n",
       "                                  &#x27;cause_of_injury_group&#x27;,\n",
       "                                  &#x27;medical_fee_region&#x27;]),\n",
       "                                (&#x27;frequencyencoder&#x27;, FrequencyEncoder(),\n",
       "                                 [&#x27;industry_code&#x27;]),\n",
       "                                (&#x27;outlier_clipper&#x27;, OutlierClipper(),\n",
       "                                 [&#x27;age_at_injury&#x27;, &#x27;ime_4_count&#x27;,\n",
       "                                  &#x27;average_weekly_wage&#x27;, &#x27;birth_year&#x27;,\n",
       "                                  &#x27;number_of_dependents&#x27;, &#x27;dd_asb_c2&#x27;,\n",
       "                                  &#x27;dd_as...\n",
       "                                  &#x27;c_2_date_month&#x27;, &#x27;c_2_date_year&#x27;,\n",
       "                                  &#x27;c_3_date_day&#x27;, &#x27;c_3_date_month&#x27;,\n",
       "                                  &#x27;c_3_date_year&#x27;, &#x27;assembly_date_day&#x27;,\n",
       "                                  &#x27;assembly_date_month&#x27;, &#x27;assembly_date_year&#x27;,\n",
       "                                  &#x27;accident_date_day&#x27;, &#x27;accident_date_month&#x27;,\n",
       "                                  &#x27;accident_date_year&#x27;, &#x27;avg_word_emb_dim_0&#x27;,\n",
       "                                  &#x27;avg_word_emb_dim_1&#x27;, &#x27;avg_word_emb_dim_2&#x27;,\n",
       "                                  &#x27;avg_word_emb_dim_3&#x27;, &#x27;avg_word_emb_dim_4&#x27;,\n",
       "                                  &#x27;avg_word_emb_dim_5&#x27;, &#x27;avg_word_emb_dim_6&#x27;, ...])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">onehotencoder</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;carrier_type&#x27;, &#x27;part_of_body_group&#x27;, &#x27;cause_of_injury_group&#x27;, &#x27;medical_fee_region&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">frequencyencoder</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;industry_code&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">FrequencyEncoder</label><div class=\"sk-toggleable__content fitted\"><pre>FrequencyEncoder()</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">outlier_clipper</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;age_at_injury&#x27;, &#x27;ime_4_count&#x27;, &#x27;average_weekly_wage&#x27;, &#x27;birth_year&#x27;, &#x27;number_of_dependents&#x27;, &#x27;dd_asb_c2&#x27;, &#x27;dd_asb_c3&#x27;, &#x27;dd_c2_c3&#x27;, &#x27;first_hearing_date_day&#x27;, &#x27;first_hearing_date_month&#x27;, &#x27;first_hearing_date_year&#x27;, &#x27;c_2_date_day&#x27;, &#x27;c_2_date_month&#x27;, &#x27;c_2_date_year&#x27;, &#x27;c_3_date_day&#x27;, &#x27;c_3_date_month&#x27;, &#x27;c_3_date_year&#x27;, &#x27;assembly_date_day&#x27;, &#x27;assembly_date_month&#x27;, &#x27;assembly_date_year&#x27;, &#x27;accident_date_day&#x27;, &#x27;accident_date_month&#x27;, &#x27;accident_date_year&#x27;, &#x27;avg_word_emb_dim_0&#x27;, &#x27;avg_word_emb_dim_1&#x27;, &#x27;avg_word_emb_dim_2&#x27;, &#x27;avg_word_emb_dim_3&#x27;, &#x27;avg_word_emb_dim_4&#x27;, &#x27;avg_word_emb_dim_5&#x27;, &#x27;avg_word_emb_dim_6&#x27;, &#x27;avg_word_emb_dim_7&#x27;, &#x27;avg_word_emb_dim_8&#x27;, &#x27;avg_word_emb_dim_9&#x27;, &#x27;var_word_emb_dim_0&#x27;, &#x27;var_word_emb_dim_1&#x27;, &#x27;var_word_emb_dim_2&#x27;, &#x27;var_word_emb_dim_3&#x27;, &#x27;var_word_emb_dim_4&#x27;, &#x27;var_word_emb_dim_5&#x27;, &#x27;var_word_emb_dim_6&#x27;, &#x27;var_word_emb_dim_7&#x27;, &#x27;var_word_emb_dim_8&#x27;, &#x27;var_word_emb_dim_9&#x27;, &#x27;euclidean_norm&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">OutlierClipper</label><div class=\"sk-toggleable__content fitted\"><pre>OutlierClipper()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MinMaxScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;KNNImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.KNNImputer.html\">?<span>Documentation for KNNImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>KNNImputer(n_neighbors=3)</pre></div> </div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;feature_selection: RFE<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_selection.RFE.html\">?<span>Documentation for feature_selection: RFE</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>RFE(estimator=ElasticNet(), n_features_to_select=50, step=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-74\" type=\"checkbox\" ><label for=\"sk-estimator-id-74\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: ElasticNet</label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-75\" type=\"checkbox\" ><label for=\"sk-estimator-id-75\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;ElasticNet<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.ElasticNet.html\">?<span>Documentation for ElasticNet</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ElasticNet()</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-76\" type=\"checkbox\" ><label for=\"sk-estimator-id-76\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">SMOTE</label><div class=\"sk-toggleable__content fitted\"><pre>SMOTE(random_state=42)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-77\" type=\"checkbox\" ><label for=\"sk-estimator-id-77\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(alpha=0.001, hidden_layer_sizes=(128, 64),\n",
       "              learning_rate_init=0.05)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('column_transformer',\n",
       "                 ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  ['carrier_type',\n",
       "                                                   'part_of_body_group',\n",
       "                                                   'cause_of_injury_group',\n",
       "                                                   'medical_fee_region']),\n",
       "                                                 ('frequencyencoder',\n",
       "                                                  FrequencyEncoder(),\n",
       "                                                  ['industry_code']),\n",
       "                                                 ('outlier_clipper',\n",
       "                                                  OutlierClipper(),\n",
       "                                                  ['age_at_injury',\n",
       "                                                   'ime_4_count',\n",
       "                                                   'average_weekly_wage',\n",
       "                                                   'birth_year',\n",
       "                                                   'nu...\n",
       "                                                   'avg_word_emb_dim_3',\n",
       "                                                   'avg_word_emb_dim_4',\n",
       "                                                   'avg_word_emb_dim_5',\n",
       "                                                   'avg_word_emb_dim_6', ...])])),\n",
       "                ('scaler', MinMaxScaler()),\n",
       "                ('knnimputer', KNNImputer(n_neighbors=3)),\n",
       "                ('feature_selection',\n",
       "                 RFE(estimator=ElasticNet(), n_features_to_select=50, step=2)),\n",
       "                ('smote', SMOTE(random_state=42)),\n",
       "                ('mlp',\n",
       "                 MLPClassifier(alpha=0.001, hidden_layer_sizes=(128, 64),\n",
       "                               learning_rate_init=0.05))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df.iloc[1]['estimator'].best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7aa288-dc41-40a2-affb-2655feb98c0f",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c145567b-8a5f-4af6-bbd7-97d2329248c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['5A. SPECIAL FUND - CONS. COMM. (SECT. 25-A)'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the best estimator from cross-validation results\u001b[39;00m\n\u001b[1;32m      2\u001b[0m best_pipeline \u001b[38;5;241m=\u001b[39m cv_results_df\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mestimator\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m----> 5\u001b[0m best_pipeline\u001b[38;5;241m.\u001b[39mpredict(test)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/imblearn/pipeline.py:459\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 459\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    462\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:1076\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1074\u001b[0m     routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_empty_routing()\n\u001b[0;32m-> 1076\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_func_on_transformers(\n\u001b[1;32m   1077\u001b[0m     X,\n\u001b[1;32m   1078\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1079\u001b[0m     _transform_one,\n\u001b[1;32m   1080\u001b[0m     column_as_labels\u001b[38;5;241m=\u001b[39mfit_dataframe_and_transform_dataframe,\n\u001b[1;32m   1081\u001b[0m     routed_params\u001b[38;5;241m=\u001b[39mrouted_params,\n\u001b[1;32m   1082\u001b[0m )\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:885\u001b[0m, in \u001b[0;36mColumnTransformer._call_func_on_transformers\u001b[0;34m(self, X, y, func, column_as_labels, routed_params)\u001b[0m\n\u001b[1;32m    873\u001b[0m             extra_args \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    874\u001b[0m         jobs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    875\u001b[0m             delayed(func)(\n\u001b[1;32m    876\u001b[0m                 transformer\u001b[38;5;241m=\u001b[39mclone(trans) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fitted \u001b[38;5;28;01melse\u001b[39;00m trans,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    882\u001b[0m             )\n\u001b[1;32m    883\u001b[0m         )\n\u001b[0;32m--> 885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(jobs)\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/pipeline.py:1290\u001b[0m, in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, params)\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1269\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call transform and apply weight to output.\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m \n\u001b[1;32m   1271\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1288\u001b[0m \u001b[38;5;124;03m        This should be of the form ``process_routing()[\"step_name\"]``.\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1290\u001b[0m     res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mtransform(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mtransform)\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:1024\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m warn_on_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrequent_if_exist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1023\u001b[0m }\n\u001b[0;32m-> 1024\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(\n\u001b[1;32m   1025\u001b[0m     X,\n\u001b[1;32m   1026\u001b[0m     handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown,\n\u001b[1;32m   1027\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1028\u001b[0m     warn_on_unknown\u001b[38;5;241m=\u001b[39mwarn_on_unknown,\n\u001b[1;32m   1029\u001b[0m )\n\u001b[1;32m   1031\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:214\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    210\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i)\n\u001b[1;32m    213\u001b[0m     )\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories ['5A. SPECIAL FUND - CONS. COMM. (SECT. 25-A)'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "# Extract the best estimator from cross-validation results\n",
    "best_pipeline = cv_results_df.iloc[1]['estimator'].best_estimator_\n",
    "\n",
    "# Fit the best pipeline on the entire dataset\n",
    "best_pipeline.fit(X, y)\n",
    "\n",
    "# Get predictions from the test set\n",
    "predictions = best_pipeline.predict(test)\n",
    "\n",
    "# Decode the predictions using the inverse mapping\n",
    "decoded_predictions = pd.Series(predictions).map(inverse_mapping)\n",
    "\n",
    "# Convert the index back to a column\n",
    "predictions_with_index = decoded_predictions.reset_index()\n",
    "\n",
    "# Export predictions with index to CSV\n",
    "predictions_with_index.to_csv('predictions_with_index.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1118191f-e7ff-4a27-b7c0-6fdc508b4e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
